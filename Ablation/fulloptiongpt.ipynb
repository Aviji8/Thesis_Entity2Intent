{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b77 full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/308 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308/308 [09:03<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to: /home/xrspace/Llama/Thesis/E2i/ablition/fulloption_predict_b77_gpt.json\n",
      "\n",
      "üîç Accuracy: 52.92%\n",
      "Mistakes: 145 / 308\n",
      "Mistakes saved to: /home/xrspace/Llama/Thesis/E2i/ablition/fulloption_mistake_b77_gpt.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load few-shot support file\n",
    "with open(\"/home/xrspace/Llama/Thesis/reduce/fs_fewshot_samples_gpt4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    FEWSHOT_DB = json.load(f)\n",
    "\n",
    "# Organize few-shot examples by label\n",
    "label_to_example = defaultdict(list)\n",
    "for entry in FEWSHOT_DB:\n",
    "    label_to_example[entry[\"true_label\"]].append(entry)\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Define full Banking77 label set\n",
    "clinc150_labels = [\n",
    "    \"activate_my_card\", \"age_limit\", \"apple_pay_or_google_pay\", \"atm_support\", \"automatic_top_up\",\n",
    "    \"balance_not_updated_after_bank_transfer\", \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    \"beneficiary_not_allowed\", \"cancel_transfer\", \"card_acceptance\", \"card_arrival\", \"card_delivery_estimate\",\n",
    "    \"card_linking\", \"card_not_working\", \"card_payment_fee_charged\", \"card_payment_not_recognised\",\n",
    "    \"card_payment_wrong_exchange_rate\", \"card_swallowed\", \"cash_withdrawal_charge\", \"cash_withdrawal_not_recognised\",\n",
    "    \"change_pin\", \"chargeback\", \"contactless_not_working\", \"country_support\", \"declined_card_payment\",\n",
    "    \"declined_cash_withdrawal\", \"declined_transfer\", \"direct_debit_payment_not_recognised\",\n",
    "    \"disposable_card_limits\", \"edit_personal_details\", \"exchange_charge\", \"exchange_rate\", \"exchange_via_app\",\n",
    "    \"extra_charge_on_statement\", \"failed_transfer\", \"fiat_currency_support\", \"get_disposable_virtual_card\",\n",
    "    \"getting_virtual_card\", \"getting_spare_card\", \"getting_new_card\", \"how_long_to_receive_card\",\n",
    "    \"how_long_to_receive_pin\", \"atm_fees\", \"lost_or_stolen_card\", \"lost_or_stolen_phone\", \"order_physical_card\",\n",
    "    \"passcode_forgotten\", \"passcode_not_working\", \"pending_card_payment\", \"pending_cash_withdrawal\",\n",
    "    \"pending_top_up\", \"pending_transfer\", \"pin_blocked\", \"receiving_money\", \"request_refund\", \"reverted_card_payment?\",\n",
    "    \"supported_cards_and_currencies\", \"terminate_account\", \"top_up_by_bank_transfer_charge\",\n",
    "    \"top_up_by_card_charge\", \"top_up_by_cash_or_cheque\", \"top_up_failed\", \"top_up_limits\", \"top_up_reverted\",\n",
    "    \"topping_up_by_card\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_into_account\",\n",
    "    \"transfer_not_received_by_recipient\", \"transfer_timing\", \"unable_to_verify_identity\", \"verify_my_identity\",\n",
    "    \"verify_source_of_funds\", \"virtual_card_not_working\", \"visa_or_mastercard\", \"why_verify_identity\",\n",
    "    \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "]\n",
    "\n",
    "# Build prompt using dynamic few-shot samples (capped at 40 total examples)\n",
    "def build_prompt(user_input: str, topn_labels: List[str]) -> str:\n",
    "    formatted_options = \"\\n\".join(f\"- {label.replace('_', ' ')}\" for label in topn_labels)\n",
    "    few_shots = []\n",
    "    MAX_FEWSHOT = 40\n",
    "\n",
    "    for label in topn_labels:\n",
    "        if label in label_to_example:\n",
    "            examples = label_to_example[label]\n",
    "            sampled = random.sample(examples, min(3, len(examples)))  # Up to 3 per label\n",
    "            for ex in sampled:\n",
    "                few_shots.append(f\"\"\"Example:\n",
    "Query: \"{ex['text']}\"\n",
    "Roles: {ex['entities']}\n",
    "Reasoning: {ex['explanation']}\n",
    "Label: {label}\n",
    "---\"\"\")\n",
    "                if len(few_shots) >= MAX_FEWSHOT:\n",
    "                    break\n",
    "        if len(few_shots) >= MAX_FEWSHOT:\n",
    "            break\n",
    "\n",
    "    few_shot_block = \"\\n\".join(few_shots)\n",
    "    return f\"\"\"You are an intelligent assistant for intent classification in banking queries.\n",
    "{few_shot_block}\n",
    "Instructions:\n",
    "1. Extract the semantic elements from the user query as structured roles:\n",
    "   - action (what is being done)\n",
    "   - object (what it‚Äôs done to)\n",
    "   - target (who or what is affected)\n",
    "   - temporal (time-related references, if any)\n",
    "   - intent_clue (phrases showing intent)\n",
    "2. Use the extracted roles to reason about how the query aligns with each of the options below.\n",
    "3. For each option, explain why it does or does not match the extracted semantics.\n",
    "4. Finally, choose the most appropriate intent label from the given options.\n",
    "5. Return final decision in the original snake_case label.\n",
    "OPTIONS:\n",
    "{formatted_options}\n",
    "---\n",
    "QUERY: {user_input}\n",
    "Respond in the following format:\n",
    "```json\n",
    "{{\n",
    "  \"roles\": {{\n",
    "    \"action\": \"...\",\n",
    "    \"object\": \"...\",\n",
    "    \"target\": \"...\",\n",
    "    \"temporal\": \"...\",\n",
    "    \"intent_clue\": \"...\"\n",
    "  }},\n",
    "  \"reasoning\": \"...\",\n",
    "  \"label\": \"...\"\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "# Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant specializing in intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=600\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Parse structured output\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    try:\n",
    "        json_part = re.search(r\"\\{.*\\}\", response, re.DOTALL).group(0)\n",
    "        parsed_json = json.loads(json_part)\n",
    "        roles = parsed_json.get(\"roles\", {})\n",
    "        explanation = parsed_json.get(\"reasoning\", \"N/A\")\n",
    "        predicted_label = parsed_json.get(\"label\", \"Unknown\")\n",
    "        return {\n",
    "            \"entities\": json.dumps(roles, ensure_ascii=False),\n",
    "            \"explanation\": explanation,\n",
    "            \"predicted_label\": predicted_label\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Parsing error:\", e)\n",
    "        return {\"entities\": \"N/A\", \"explanation\": \"N/A\", \"predicted_label\": \"Unknown\"}\n",
    "\n",
    "# Main evaluation pipeline\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)#.iloc[:10]\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row[\"text\"]\n",
    "        true_label = row[\"label\"]\n",
    "        prompt = build_prompt(text, clinc150_labels)  # Full label set\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        results.append({\n",
    "            \"id\": int(row[\"id\"]),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": clinc150_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        })\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to: {output_json}\")\n",
    "    return results\n",
    "\n",
    "# Accuracy check\n",
    "def evaluate_accuracy(results: List[Dict], mistake_file: str = \"e2i_macc_b77_mistakes-turbo.json\"):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r[\"true_label\"].strip() == r[\"predicted_label\"].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    mistakes = [r for r in results if r[\"true_label\"].strip() != r[\"predicted_label\"].strip()]\n",
    "    print(f\"\\nüîç Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"Mistakes: {len(mistakes)} / {total}\")\n",
    "    if mistakes:\n",
    "        with open(mistake_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Mistakes saved to: {mistake_file}\")\n",
    "    else:\n",
    "        print(\"üéâ No mistakes! Perfect predictions.\")\n",
    "    return accuracy\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/maccot_topk_formatted.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fulloption_predict_b77_gpt.json\"\n",
    "    mistake_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fulloption_mistake_b77_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results, mistake_file=mistake_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fs flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308/308 [02:58<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to /home/xrspace/Llama/Thesis/E2i/ablition/fs_alloption_prediction_gpt.json\n",
      "\n",
      "üìä Accuracy Report\n",
      "Total Samples: 308\n",
      "Correct Predictions: 124\n",
      "Accuracy: 40.26%\n",
      "\n",
      "üîç 184 mistakes saved to fs_alloption_mistake_gpt.json.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Load few-shot examples\n",
    "with open(\"/home/xrspace/Llama/Thesis/reduce/fs_fewshot_samples_gpt4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    FEWSHOT_DB = json.load(f)\n",
    "\n",
    "label_to_example = defaultdict(list)\n",
    "for entry in FEWSHOT_DB:\n",
    "    label_to_example[entry[\"true_label\"]].append(entry)\n",
    "\n",
    "# Full Banking77 label set\n",
    "banking77_labels = [\n",
    "    \"activate_my_card\", \"age_limit\", \"apple_pay_or_google_pay\", \"atm_support\", \"automatic_top_up\",\n",
    "    \"balance_not_updated_after_bank_transfer\", \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    \"beneficiary_not_allowed\", \"cancel_transfer\", \"card_acceptance\", \"card_arrival\", \"card_delivery_estimate\",\n",
    "    \"card_linking\", \"card_not_working\", \"card_payment_fee_charged\", \"card_payment_not_recognised\",\n",
    "    \"card_payment_wrong_exchange_rate\", \"card_swallowed\", \"cash_withdrawal_charge\", \"cash_withdrawal_not_recognised\",\n",
    "    \"change_pin\", \"chargeback\", \"contactless_not_working\", \"country_support\", \"declined_card_payment\",\n",
    "    \"declined_cash_withdrawal\", \"declined_transfer\", \"direct_debit_payment_not_recognised\",\n",
    "    \"disposable_card_limits\", \"edit_personal_details\", \"exchange_charge\", \"exchange_rate\", \"exchange_via_app\",\n",
    "    \"extra_charge_on_statement\", \"failed_transfer\", \"fiat_currency_support\", \"get_disposable_virtual_card\",\n",
    "    \"getting_virtual_card\", \"getting_spare_card\", \"getting_new_card\", \"how_long_to_receive_card\",\n",
    "    \"how_long_to_receive_pin\", \"atm_fees\", \"lost_or_stolen_card\", \"lost_or_stolen_phone\", \"order_physical_card\",\n",
    "    \"passcode_forgotten\", \"passcode_not_working\", \"pending_card_payment\", \"pending_cash_withdrawal\",\n",
    "    \"pending_top_up\", \"pending_transfer\", \"pin_blocked\", \"receiving_money\", \"request_refund\", \"reverted_card_payment?\",\n",
    "    \"supported_cards_and_currencies\", \"terminate_account\", \"top_up_by_bank_transfer_charge\",\n",
    "    \"top_up_by_card_charge\", \"top_up_by_cash_or_cheque\", \"top_up_failed\", \"top_up_limits\", \"top_up_reverted\",\n",
    "    \"topping_up_by_card\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_into_account\",\n",
    "    \"transfer_not_received_by_recipient\", \"transfer_timing\", \"unable_to_verify_identity\", \"verify_my_identity\",\n",
    "    \"verify_source_of_funds\", \"virtual_card_not_working\", \"visa_or_mastercard\", \"why_verify_identity\",\n",
    "    \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "]\n",
    "\n",
    "# 1. Build prompt using all 77 labels\n",
    "def build_prompt(user_input: str) -> str:\n",
    "    few_shots = []\n",
    "    added_labels = set()\n",
    "\n",
    "    for label in clinc150_labels:\n",
    "        if label in label_to_example and label not in added_labels:\n",
    "            ex = label_to_example[label][0]\n",
    "            few_shots.append(f\"SENTENCE: {ex['text']}\\nLABEL: {label}\")\n",
    "            added_labels.add(label)\n",
    "        if len(few_shots) == 2:\n",
    "            break\n",
    "\n",
    "    few_shot_block = \"\\n\\n\".join(few_shots)\n",
    "    options_block = \", \".join(clinc150_labels)\n",
    "\n",
    "    prompt = f\"\"\"Below is a text classification problem.\n",
    "Note that you can only select the label in\n",
    "{{{options_block}}}\n",
    "\n",
    "{few_shot_block}\n",
    "\n",
    "SENTENCE: {user_input}\n",
    "LABEL:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 2. Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 3. Parse response\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"entities\": \"N/A\",\n",
    "        \"explanation\": \"N/A\",\n",
    "        \"predicted_label\": response.strip().split(\"\\n\")[0]\n",
    "    }\n",
    "\n",
    "# 4. Run classification on 10 samples\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)#.iloc[:10]  # Limit to first 10\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['text']\n",
    "        true_label = row['label']\n",
    "        prompt = build_prompt(text)  # Use full label set\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        result = {\n",
    "            \"id\": int(row['id']),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": banking77_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        }\n",
    "        results.append(result)\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to {output_json}\")\n",
    "    return results\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "def evaluate_accuracy(results: List[Dict]):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['true_label'].strip() == r['predicted_label'].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    print(\"\\nüìä Accuracy Report\")\n",
    "    print(f\"Total Samples: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    mistakes = [r for r in results if r['true_label'].strip() != r['predicted_label'].strip()]\n",
    "    if mistakes:\n",
    "        with open(\"/home/xrspace/Llama/Thesis/E2i/ablition/fs_alloption_mistake_gpt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nüîç {len(mistakes)} mistakes saved to fs_alloption_mistake_gpt.json.json\")\n",
    "    return accuracy\n",
    "\n",
    "# 6. Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_b77_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fs_alloption_prediction_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Load few-shot examples\n",
    "with open(\"/home/xrspace/Llama/Thesis/reduce/fs_fewshot_samples_gpt4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    FEWSHOT_DB = json.load(f)\n",
    "\n",
    "label_to_example = defaultdict(list)\n",
    "for entry in FEWSHOT_DB:\n",
    "    label_to_example[entry[\"true_label\"]].append(entry)\n",
    "\n",
    "# Full Banking77 label set\n",
    "banking77_labels = [\n",
    "    \"activate_my_card\", \"age_limit\", \"apple_pay_or_google_pay\", \"atm_support\", \"automatic_top_up\",\n",
    "    \"balance_not_updated_after_bank_transfer\", \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    \"beneficiary_not_allowed\", \"cancel_transfer\", \"card_acceptance\", \"card_arrival\", \"card_delivery_estimate\",\n",
    "    \"card_linking\", \"card_not_working\", \"card_payment_fee_charged\", \"card_payment_not_recognised\",\n",
    "    \"card_payment_wrong_exchange_rate\", \"card_swallowed\", \"cash_withdrawal_charge\", \"cash_withdrawal_not_recognised\",\n",
    "    \"change_pin\", \"chargeback\", \"contactless_not_working\", \"country_support\", \"declined_card_payment\",\n",
    "    \"declined_cash_withdrawal\", \"declined_transfer\", \"direct_debit_payment_not_recognised\",\n",
    "    \"disposable_card_limits\", \"edit_personal_details\", \"exchange_charge\", \"exchange_rate\", \"exchange_via_app\",\n",
    "    \"extra_charge_on_statement\", \"failed_transfer\", \"fiat_currency_support\", \"get_disposable_virtual_card\",\n",
    "    \"getting_virtual_card\", \"getting_spare_card\", \"getting_new_card\", \"how_long_to_receive_card\",\n",
    "    \"how_long_to_receive_pin\", \"atm_fees\", \"lost_or_stolen_card\", \"lost_or_stolen_phone\", \"order_physical_card\",\n",
    "    \"passcode_forgotten\", \"passcode_not_working\", \"pending_card_payment\", \"pending_cash_withdrawal\",\n",
    "    \"pending_top_up\", \"pending_transfer\", \"pin_blocked\", \"receiving_money\", \"request_refund\", \"reverted_card_payment?\",\n",
    "    \"supported_cards_and_currencies\", \"terminate_account\", \"top_up_by_bank_transfer_charge\",\n",
    "    \"top_up_by_card_charge\", \"top_up_by_cash_or_cheque\", \"top_up_failed\", \"top_up_limits\", \"top_up_reverted\",\n",
    "    \"topping_up_by_card\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_into_account\",\n",
    "    \"transfer_not_received_by_recipient\", \"transfer_timing\", \"unable_to_verify_identity\", \"verify_my_identity\",\n",
    "    \"verify_source_of_funds\", \"virtual_card_not_working\", \"visa_or_mastercard\", \"why_verify_identity\",\n",
    "    \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "]\n",
    "\n",
    "# 1. Build prompt using all 77 labels\n",
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Load few-shot examples\n",
    "with open(\"/home/xrspace/Llama/Thesis/reduce/fs_fewshot_samples_gpt4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    FEWSHOT_DB = json.load(f)\n",
    "\n",
    "label_to_example = defaultdict(list)\n",
    "for entry in FEWSHOT_DB:\n",
    "    label_to_example[entry[\"true_label\"]].append(entry)\n",
    "\n",
    "# Full Banking77 label set\n",
    "banking77_labels = [\n",
    "    \"activate_my_card\", \"age_limit\", \"apple_pay_or_google_pay\", \"atm_support\", \"automatic_top_up\",\n",
    "    \"balance_not_updated_after_bank_transfer\", \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    \"beneficiary_not_allowed\", \"cancel_transfer\", \"card_acceptance\", \"card_arrival\", \"card_delivery_estimate\",\n",
    "    \"card_linking\", \"card_not_working\", \"card_payment_fee_charged\", \"card_payment_not_recognised\",\n",
    "    \"card_payment_wrong_exchange_rate\", \"card_swallowed\", \"cash_withdrawal_charge\", \"cash_withdrawal_not_recognised\",\n",
    "    \"change_pin\", \"chargeback\", \"contactless_not_working\", \"country_support\", \"declined_card_payment\",\n",
    "    \"declined_cash_withdrawal\", \"declined_transfer\", \"direct_debit_payment_not_recognised\",\n",
    "    \"disposable_card_limits\", \"edit_personal_details\", \"exchange_charge\", \"exchange_rate\", \"exchange_via_app\",\n",
    "    \"extra_charge_on_statement\", \"failed_transfer\", \"fiat_currency_support\", \"get_disposable_virtual_card\",\n",
    "    \"getting_virtual_card\", \"getting_spare_card\", \"getting_new_card\", \"how_long_to_receive_card\",\n",
    "    \"how_long_to_receive_pin\", \"atm_fees\", \"lost_or_stolen_card\", \"lost_or_stolen_phone\", \"order_physical_card\",\n",
    "    \"passcode_forgotten\", \"passcode_not_working\", \"pending_card_payment\", \"pending_cash_withdrawal\",\n",
    "    \"pending_top_up\", \"pending_transfer\", \"pin_blocked\", \"receiving_money\", \"request_refund\", \"reverted_card_payment?\",\n",
    "    \"supported_cards_and_currencies\", \"terminate_account\", \"top_up_by_bank_transfer_charge\",\n",
    "    \"top_up_by_card_charge\", \"top_up_by_cash_or_cheque\", \"top_up_failed\", \"top_up_limits\", \"top_up_reverted\",\n",
    "    \"topping_up_by_card\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_into_account\",\n",
    "    \"transfer_not_received_by_recipient\", \"transfer_timing\", \"unable_to_verify_identity\", \"verify_my_identity\",\n",
    "    \"verify_source_of_funds\", \"virtual_card_not_working\", \"visa_or_mastercard\", \"why_verify_identity\",\n",
    "    \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "]\n",
    "\n",
    "# 1. Build prompt using all 77 labels\n",
    "def build_prompt(user_input: str) -> str:\n",
    "    few_shots = []\n",
    "    added_labels = set()\n",
    "\n",
    "    for label in banking77_labels:\n",
    "        if label in label_to_example and label not in added_labels:\n",
    "            ex = label_to_example[label][0]\n",
    "            few_shots.append(f\"SENTENCE: {ex['text']}\\nLABEL: {label}\")\n",
    "            added_labels.add(label)\n",
    "        if len(few_shots) == 2:\n",
    "            break\n",
    "\n",
    "    few_shot_block = \"\\n\\n\".join(few_shots)\n",
    "    options_block = \", \".join(banking77_labels)\n",
    "\n",
    "    prompt = f\"\"\"Below is a text classification problem.\n",
    "Note that you can only select the label in\n",
    "{{{options_block}}}\n",
    "\n",
    "{few_shot_block}\n",
    "\n",
    "SENTENCE: {user_input}\n",
    "LABEL:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 2. Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 3. Parse response\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"entities\": \"N/A\",\n",
    "        \"explanation\": \"N/A\",\n",
    "        \"predicted_label\": response.strip().split(\"\\n\")[0]\n",
    "    }\n",
    "\n",
    "# 4. Run classification on 10 samples\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)#.iloc[:10]  # Limit to first 10\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['text']\n",
    "        true_label = row['label']\n",
    "        prompt = build_prompt(text)  # Use full label set\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        result = {\n",
    "            \"id\": int(row['id']),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": banking77_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        }\n",
    "        results.append(result)\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to {output_json}\")\n",
    "    return results\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "def evaluate_accuracy(results: List[Dict]):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['true_label'].strip() == r['predicted_label'].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    print(\"\\nüìä Accuracy Report\")\n",
    "    print(f\"Total Samples: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    mistakes = [r for r in results if r['true_label'].strip() != r['predicted_label'].strip()]\n",
    "    if mistakes:\n",
    "        with open(\"/home/xrspace/Llama/Thesis/E2i/ablition/fs_alloption_mistake_gpt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nüîç {len(mistakes)} mistakes saved to fs_alloption_mistake_gpt.json.json\")\n",
    "    return accuracy\n",
    "\n",
    "# 6. Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_b77_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fs_alloption_prediction_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results)\n",
    "\n",
    "# 2. Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 3. Parse response\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"entities\": \"N/A\",\n",
    "        \"explanation\": \"N/A\",\n",
    "        \"predicted_label\": response.strip().split(\"\\n\")[0]\n",
    "    }\n",
    "\n",
    "# 4. Run classification on 10 samples\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)#.iloc[:10]  # Limit to first 10\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['text']\n",
    "        true_label = row['label']\n",
    "        prompt = build_prompt(text)  # Use full label set\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        result = {\n",
    "            \"id\": int(row['id']),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": banking77_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        }\n",
    "        results.append(result)\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to {output_json}\")\n",
    "    return results\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "def evaluate_accuracy(results: List[Dict]):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['true_label'].strip() == r['predicted_label'].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    print(\"\\nüìä Accuracy Report\")\n",
    "    print(f\"Total Samples: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    mistakes = [r for r in results if r['true_label'].strip() != r['predicted_label'].strip()]\n",
    "    if mistakes:\n",
    "        with open(\"/home/xrspace/Llama/Thesis/E2i/ablition/fs_alloption_mistake_gpt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nüîç {len(mistakes)} mistakes saved to fs_alloption_mistake_gpt.json.json\")\n",
    "    return accuracy\n",
    "\n",
    "# 6. Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_b77_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fs_alloption_prediction_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308/308 [03:07<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to /home/xrspace/Llama/Thesis/E2i/ablition/zs_alloption_prediction_gpt.json\n",
      "\n",
      "üìä Accuracy Report\n",
      "Total Samples: 308\n",
      "Correct Predictions: 79\n",
      "Accuracy: 25.65%\n",
      "\n",
      "üîç 229 mistakes saved to zs_alloption_mistake_gpt.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Full Banking77 label set\n",
    "banking77_labels = [\n",
    "    \"activate_my_card\", \"age_limit\", \"apple_pay_or_google_pay\", \"atm_support\", \"automatic_top_up\",\n",
    "    \"balance_not_updated_after_bank_transfer\", \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    \"beneficiary_not_allowed\", \"cancel_transfer\", \"card_acceptance\", \"card_arrival\", \"card_delivery_estimate\",\n",
    "    \"card_linking\", \"card_not_working\", \"card_payment_fee_charged\", \"card_payment_not_recognised\",\n",
    "    \"card_payment_wrong_exchange_rate\", \"card_swallowed\", \"cash_withdrawal_charge\", \"cash_withdrawal_not_recognised\",\n",
    "    \"change_pin\", \"chargeback\", \"contactless_not_working\", \"country_support\", \"declined_card_payment\",\n",
    "    \"declined_cash_withdrawal\", \"declined_transfer\", \"direct_debit_payment_not_recognised\",\n",
    "    \"disposable_card_limits\", \"edit_personal_details\", \"exchange_charge\", \"exchange_rate\", \"exchange_via_app\",\n",
    "    \"extra_charge_on_statement\", \"failed_transfer\", \"fiat_currency_support\", \"get_disposable_virtual_card\",\n",
    "    \"getting_virtual_card\", \"getting_spare_card\", \"getting_new_card\", \"how_long_to_receive_card\",\n",
    "    \"how_long_to_receive_pin\", \"atm_fees\", \"lost_or_stolen_card\", \"lost_or_stolen_phone\", \"order_physical_card\",\n",
    "    \"passcode_forgotten\", \"passcode_not_working\", \"pending_card_payment\", \"pending_cash_withdrawal\",\n",
    "    \"pending_top_up\", \"pending_transfer\", \"pin_blocked\", \"receiving_money\", \"request_refund\", \"reverted_card_payment?\",\n",
    "    \"supported_cards_and_currencies\", \"terminate_account\", \"top_up_by_bank_transfer_charge\",\n",
    "    \"top_up_by_card_charge\", \"top_up_by_cash_or_cheque\", \"top_up_failed\", \"top_up_limits\", \"top_up_reverted\",\n",
    "    \"topping_up_by_card\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_into_account\",\n",
    "    \"transfer_not_received_by_recipient\", \"transfer_timing\", \"unable_to_verify_identity\", \"verify_my_identity\",\n",
    "    \"verify_source_of_funds\", \"virtual_card_not_working\", \"visa_or_mastercard\", \"why_verify_identity\",\n",
    "    \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "]\n",
    "\n",
    "# 1. Build Zero-Shot prompt\n",
    "def build_prompt(user_input: str) -> str:\n",
    "    options_block = \", \".join(banking77_labels)\n",
    "    return f\"\"\"Given the sentence: \"{user_input}\"\n",
    "Please select the most possible topic from\n",
    "the following OPTIONS: {options_block}\n",
    "CHOICE:\"\"\"\n",
    "\n",
    "# 2. Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 3. Parse response\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"entities\": \"N/A\",\n",
    "        \"explanation\": \"N/A\",\n",
    "        \"predicted_label\": response.strip().split(\"\\n\")[0]\n",
    "    }\n",
    "\n",
    "# 4. Run classification\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)  # ‚Üê run on all samples; or use .iloc[:10] to limit\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['text']\n",
    "        true_label = row['label']\n",
    "        prompt = build_prompt(text)\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        result = {\n",
    "            \"id\": int(row['id']),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": banking77_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        }\n",
    "        results.append(result)\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to {output_json}\")\n",
    "    return results\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "def evaluate_accuracy(results: List[Dict]):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['true_label'].strip() == r['predicted_label'].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    print(\"\\nüìä Accuracy Report\")\n",
    "    print(f\"Total Samples: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    mistakes = [r for r in results if r['true_label'].strip() != r['predicted_label'].strip()]\n",
    "    if mistakes:\n",
    "        with open(\"/home/xrspace/Llama/Thesis/E2i/ablition/zs_alloption_mistake_gpt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nüîç {len(mistakes)} mistakes saved to zs_alloption_mistake_gpt.json\")\n",
    "    return accuracy\n",
    "\n",
    "# 6. Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_b77_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/zs_alloption_prediction_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "click\n",
    "full option e2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [06:42<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to: /home/xrspace/Llama/Thesis/E2i/ablition/fulloption_predict_clinc_gpt.json\n",
      "\n",
      "üîç Accuracy: 53.78%\n",
      "Mistakes: 104 / 225\n",
      "Mistakes saved to: /home/xrspace/Llama/Thesis/E2i/ablition/fulloption_mistake_clinc_gpt.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load few-shot support file\n",
    "with open(\"/home/xrspace/Llama/Thesis/reduce/clinc/fs_clinc_samples_gpt4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    FEWSHOT_DB = json.load(f)\n",
    "\n",
    "# Organize few-shot examples by label\n",
    "label_to_example = defaultdict(list)\n",
    "for entry in FEWSHOT_DB:\n",
    "    label_to_example[entry[\"true_label\"]].append(entry)\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Define full Banking77 label set\n",
    "clinc150_labels = [\n",
    "    \"restaurant_reviews\", \"nutrition_info\", \"account_blocked\", \"oil_change_how\", \"time\",\n",
    "    \"weather\", \"redeem_rewards\", \"interest_rate\", \"gas_type\", \"accept_reservations\",\n",
    "    \"smart_home\", \"user_name\", \"report_lost_card\", \"repeat\", \"give_weather\",\n",
    "    \"credit_limit_change\", \"change_language\", \"update_playlist\", \"sync_device\", \"schedule_maintenance\",\n",
    "    \"what_are_your_hobbies\", \"book_hotel\", \"cancel_reservation\", \"change_accent\", \"min_payment\",\n",
    "    \"pay_bill\", \"international_visa\", \"calendar\", \"exchange_rate\", \"flip_coin\",\n",
    "    \"do_you_have_pets\", \"balance\", \"tell_joke\", \"last_maintenance\", \"income\",\n",
    "    \"vaccines\", \"reminder_update\", \"order\", \"jump_start\", \"recipe\",\n",
    "    \"meal_suggestion\", \"restaurant_reservation\", \"reset_password\", \"change_password\", \"spending_history\",\n",
    "    \"cancel\", \"user_rating\", \"where_are_you_from\", \"are_you_a_bot\", \"make_reservation\",\n",
    "    \"expiration_date\", \"routing\", \"insurance_change\", \"what_is_your_name\", \"thank_you\",\n",
    "    \"shopping_list\", \"user_feedback\", \"change_speed\", \"plug_type\", \"travel_alert\",\n",
    "    \"traffic\", \"travel_notification\", \"order_checks\", \"bill_balance\", \"improve_credit_score\",\n",
    "    \"report_fraud\", \"spending_limit\", \"directions\", \"credit_score\", \"bill_due\",\n",
    "    \"who_made_you\", \"application_status\", \"apr\", \"how_old_are_you\", \"are_you_real\",\n",
    "    \"direct_deposit\", \"transactions\", \"transfer\", \"card_declined\", \"interest_rate_change\",\n",
    "    \"report_lost_phone\", \"change_user_name\", \"current_location\", \"pto_request\", \"next_song\",\n",
    "    \"change_volume\", \"travel_suggestion\", \"no\", \"maybe\", \"yes\",\n",
    "    \"order_status\", \"confirm_reservation\", \"cook_time\", \"calendar_update\", \"nutrition_plan\",\n",
    "    \"pto_request_status\", \"how_busy\", \"cancel_subscription\", \"exchange_currency\", \"payday\",\n",
    "    \"schedule_meeting\", \"calories\", \"report_charge\", \"car_rental\", \"gas\",\n",
    "    \"how_much\", \"play_music\", \"book_flight\", \"weather_umbrella\", \"book_holiday\",\n",
    "    \"uber\", \"change_organization\", \"meeting_schedule\", \"whisper_mode\", \"what_song\",\n",
    "    \"meaning_of_life\", \"todo_list\", \"card_arrival\", \"next_holiday\", \"change_name\",\n",
    "    \"international_fees\", \"calendar_remove\", \"taxes\", \"vaccination_requirements\", \"passport_renewal\",\n",
    "    \"timezone\", \"reminder\", \"how_many\", \"application_deadline\", \"freeze_account\",\n",
    "    \"what_can_i_ask_you\", \"give_recipe\", \"start_plan\", \"goodbye\", \"what_is_your_gender\",\n",
    "    \"how_do_i_make_a_payment\", \"book_appointment\", \"damaged_card\", \"reset_settings\", \"update_settings\",\n",
    "    \"pto_balance\", \"cancel_appointment\", \"order_cancel\", \"cut_off\", \"report_outage\",\n",
    "    \"reward_balance\", \"update_profile\", \"add_remove_device\", \"fun_fact\", \"oil_change_when\",\n",
    "    \"travel_documents\", \"replacement_card_duration\", \"new_card\", \"roll_dice\", \"who_do_you_work_for\",\n",
    "    \"shopping_list_update\", \"next_event\", \"change_profile_picture\", \"redeem_gift_card\", \"current_weather\",\n",
    "    \"flight_status\", \"new_card_limit\", \"good_morning\", \"new_card_expires\", \"how_long\",\n",
    "    \"where_is_my_refund\", \"definition\", \"bill_due_date\", \"who_are_you\", \"tell_me_about_yourself\"\n",
    "]\n",
    "\n",
    "# Build prompt using dynamic few-shot samples (capped at 40 total examples)\n",
    "def build_prompt(user_input: str, topn_labels: List[str]) -> str:\n",
    "    formatted_options = \"\\n\".join(f\"- {label.replace('_', ' ')}\" for label in topn_labels)\n",
    "    few_shots = []\n",
    "    MAX_FEWSHOT = 40\n",
    "\n",
    "    for label in topn_labels:\n",
    "        if label in label_to_example:\n",
    "            examples = label_to_example[label]\n",
    "            sampled = random.sample(examples, min(3, len(examples)))  # Up to 3 per label\n",
    "            for ex in sampled:\n",
    "                few_shots.append(f\"\"\"Example:\n",
    "Query: \"{ex['text']}\"\n",
    "Roles: {ex['entities']}\n",
    "Reasoning: {ex['explanation']}\n",
    "Label: {label}\n",
    "---\"\"\")\n",
    "                if len(few_shots) >= MAX_FEWSHOT:\n",
    "                    break\n",
    "        if len(few_shots) >= MAX_FEWSHOT:\n",
    "            break\n",
    "\n",
    "    few_shot_block = \"\\n\".join(few_shots)\n",
    "    return f\"\"\"You are an intelligent assistant for intent classification in banking queries.\n",
    "{few_shot_block}\n",
    "Instructions:\n",
    "1. Extract the semantic elements from the user query as structured roles:\n",
    "   - action (what is being done)\n",
    "   - object (what it‚Äôs done to)\n",
    "   - target (who or what is affected)\n",
    "   - temporal (time-related references, if any)\n",
    "   - intent_clue (phrases showing intent)\n",
    "2. Use the extracted roles to reason about how the query aligns with each of the options below.\n",
    "3. For each option, explain why it does or does not match the extracted semantics.\n",
    "4. Finally, choose the most appropriate intent label from the given options.\n",
    "5. Return final decision in the original snake_case label.\n",
    "OPTIONS:\n",
    "{formatted_options}\n",
    "---\n",
    "QUERY: {user_input}\n",
    "Respond in the following format:\n",
    "```json\n",
    "{{\n",
    "  \"roles\": {{\n",
    "    \"action\": \"...\",\n",
    "    \"object\": \"...\",\n",
    "    \"target\": \"...\",\n",
    "    \"temporal\": \"...\",\n",
    "    \"intent_clue\": \"...\"\n",
    "  }},\n",
    "  \"reasoning\": \"...\",\n",
    "  \"label\": \"...\"\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "# Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant specializing in intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=600\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Parse structured output\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    try:\n",
    "        json_part = re.search(r\"\\{.*\\}\", response, re.DOTALL).group(0)\n",
    "        parsed_json = json.loads(json_part)\n",
    "        roles = parsed_json.get(\"roles\", {})\n",
    "        explanation = parsed_json.get(\"reasoning\", \"N/A\")\n",
    "        predicted_label = parsed_json.get(\"label\", \"Unknown\")\n",
    "        return {\n",
    "            \"entities\": json.dumps(roles, ensure_ascii=False),\n",
    "            \"explanation\": explanation,\n",
    "            \"predicted_label\": predicted_label\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Parsing error:\", e)\n",
    "        return {\"entities\": \"N/A\", \"explanation\": \"N/A\", \"predicted_label\": \"Unknown\"}\n",
    "\n",
    "# Main evaluation pipeline\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)#.iloc[:10]\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row[\"text\"]\n",
    "        true_label = row[\"label\"]\n",
    "        prompt = build_prompt(text, clinc150_labels)  # Full label set\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        results.append({\n",
    "            \"id\": int(row[\"id\"]),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": clinc150_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        })\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to: {output_json}\")\n",
    "    return results\n",
    "\n",
    "# Accuracy check\n",
    "def evaluate_accuracy(results: List[Dict], mistake_file: str = \"fulloption_mistake_clinc_gpt.json\"):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r[\"true_label\"].strip() == r[\"predicted_label\"].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    mistakes = [r for r in results if r[\"true_label\"].strip() != r[\"predicted_label\"].strip()]\n",
    "    print(f\"\\nüîç Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"Mistakes: {len(mistakes)} / {total}\")\n",
    "    if mistakes:\n",
    "        with open(mistake_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Mistakes saved to: {mistake_file}\")\n",
    "    else:\n",
    "        print(\"üéâ No mistakes! Perfect predictions.\")\n",
    "    return accuracy\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_formatted_clinc_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fulloption_predict_clinc_gpt.json\"\n",
    "    mistake_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fulloption_mistake_clinc_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results, mistake_file=mistake_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clincfsfull option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [02:01<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to /home/xrspace/Llama/Thesis/E2i/ablition/fs_fulloption_predict_clinc_gpt.json\n",
      "\n",
      "üìä Accuracy Report\n",
      "Total Samples: 225\n",
      "Correct Predictions: 86\n",
      "Accuracy: 38.22%\n",
      "\n",
      "üîç 139 mistakes saved to fs_alloption_mistake_gpt.json.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Load few-shot examples\n",
    "with open(\"/home/xrspace/Llama/Thesis/reduce/clinc/fs_clinc_samples_gpt4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    FEWSHOT_DB = json.load(f)\n",
    "\n",
    "label_to_example = defaultdict(list)\n",
    "for entry in FEWSHOT_DB:\n",
    "    label_to_example[entry[\"true_label\"]].append(entry)\n",
    "\n",
    "# Full Banking77 label set\n",
    "clinc150_labels = [\n",
    "\"restaurant_reviews\", \"nutrition_info\", \"account_blocked\", \"oil_change_how\", \"time\",\n",
    "    \"weather\", \"redeem_rewards\", \"interest_rate\", \"gas_type\", \"accept_reservations\",\n",
    "    \"smart_home\", \"user_name\", \"report_lost_card\", \"repeat\", \"give_weather\",\n",
    "    \"credit_limit_change\", \"change_language\", \"update_playlist\", \"sync_device\", \"schedule_maintenance\",\n",
    "    \"what_are_your_hobbies\", \"book_hotel\", \"cancel_reservation\", \"change_accent\", \"min_payment\",\n",
    "    \"pay_bill\", \"international_visa\", \"calendar\", \"exchange_rate\", \"flip_coin\",\n",
    "    \"do_you_have_pets\", \"balance\", \"tell_joke\", \"last_maintenance\", \"income\",\n",
    "    \"vaccines\", \"reminder_update\", \"order\", \"jump_start\", \"recipe\",\n",
    "    \"meal_suggestion\", \"restaurant_reservation\", \"reset_password\", \"change_password\", \"spending_history\",\n",
    "    \"cancel\", \"user_rating\", \"where_are_you_from\", \"are_you_a_bot\", \"make_reservation\",\n",
    "    \"expiration_date\", \"routing\", \"insurance_change\", \"what_is_your_name\", \"thank_you\",\n",
    "    \"shopping_list\", \"user_feedback\", \"change_speed\", \"plug_type\", \"travel_alert\",\n",
    "    \"traffic\", \"travel_notification\", \"order_checks\", \"bill_balance\", \"improve_credit_score\",\n",
    "    \"report_fraud\", \"spending_limit\", \"directions\", \"credit_score\", \"bill_due\",\n",
    "    \"who_made_you\", \"application_status\", \"apr\", \"how_old_are_you\", \"are_you_real\",\n",
    "    \"direct_deposit\", \"transactions\", \"transfer\", \"card_declined\", \"interest_rate_change\",\n",
    "    \"report_lost_phone\", \"change_user_name\", \"current_location\", \"pto_request\", \"next_song\",\n",
    "    \"change_volume\", \"travel_suggestion\", \"no\", \"maybe\", \"yes\",\n",
    "    \"order_status\", \"confirm_reservation\", \"cook_time\", \"calendar_update\", \"nutrition_plan\",\n",
    "    \"pto_request_status\", \"how_busy\", \"cancel_subscription\", \"exchange_currency\", \"payday\",\n",
    "    \"schedule_meeting\", \"calories\", \"report_charge\", \"car_rental\", \"gas\",\n",
    "    \"how_much\", \"play_music\", \"book_flight\", \"weather_umbrella\", \"book_holiday\",\n",
    "    \"uber\", \"change_organization\", \"meeting_schedule\", \"whisper_mode\", \"what_song\",\n",
    "    \"meaning_of_life\", \"todo_list\", \"card_arrival\", \"next_holiday\", \"change_name\",\n",
    "    \"international_fees\", \"calendar_remove\", \"taxes\", \"vaccination_requirements\", \"passport_renewal\",\n",
    "    \"timezone\", \"reminder\", \"how_many\", \"application_deadline\", \"freeze_account\",\n",
    "    \"what_can_i_ask_you\", \"give_recipe\", \"start_plan\", \"goodbye\", \"what_is_your_gender\",\n",
    "    \"how_do_i_make_a_payment\", \"book_appointment\", \"damaged_card\", \"reset_settings\", \"update_settings\",\n",
    "    \"pto_balance\", \"cancel_appointment\", \"order_cancel\", \"cut_off\", \"report_outage\",\n",
    "    \"reward_balance\", \"update_profile\", \"add_remove_device\", \"fun_fact\", \"oil_change_when\",\n",
    "    \"travel_documents\", \"replacement_card_duration\", \"new_card\", \"roll_dice\", \"who_do_you_work_for\",\n",
    "    \"shopping_list_update\", \"next_event\", \"change_profile_picture\", \"redeem_gift_card\", \"current_weather\",\n",
    "    \"flight_status\", \"new_card_limit\", \"good_morning\", \"new_card_expires\", \"how_long\",\n",
    "    \"where_is_my_refund\", \"definition\", \"bill_due_date\", \"who_are_you\", \"tell_me_about_yourself\"\n",
    "]\n",
    "\n",
    "# 1. Build prompt using all 77 labels\n",
    "def build_prompt(user_input: str) -> str:\n",
    "    few_shots = []\n",
    "    added_labels = set()\n",
    "\n",
    "    for label in clinc150_labels:\n",
    "        if label in label_to_example and label not in added_labels:\n",
    "            ex = label_to_example[label][0]\n",
    "            few_shots.append(f\"SENTENCE: {ex['text']}\\nLABEL: {label}\")\n",
    "            added_labels.add(label)\n",
    "        if len(few_shots) == 2:\n",
    "            break\n",
    "\n",
    "    few_shot_block = \"\\n\\n\".join(few_shots)\n",
    "    options_block = \", \".join(clinc150_labels)\n",
    "\n",
    "    prompt = f\"\"\"Below is a text classification problem.\n",
    "Note that you can only select the label in\n",
    "{{{options_block}}}\n",
    "\n",
    "{few_shot_block}\n",
    "\n",
    "SENTENCE: {user_input}\n",
    "LABEL:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 2. Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 3. Parse response\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"entities\": \"N/A\",\n",
    "        \"explanation\": \"N/A\",\n",
    "        \"predicted_label\": response.strip().split(\"\\n\")[0]\n",
    "    }\n",
    "\n",
    "# 4. Run classification on 10 samples\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)#.iloc[:10]  # Limit to first 10\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['text']\n",
    "        true_label = row['label']\n",
    "        prompt = build_prompt(text)  # Use full label set\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        result = {\n",
    "            \"id\": int(row['id']),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": clinc150_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        }\n",
    "        results.append(result)\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to {output_json}\")\n",
    "    return results\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "def evaluate_accuracy(results: List[Dict]):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['true_label'].strip() == r['predicted_label'].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    print(\"\\nüìä Accuracy Report\")\n",
    "    print(f\"Total Samples: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    mistakes = [r for r in results if r['true_label'].strip() != r['predicted_label'].strip()]\n",
    "    if mistakes:\n",
    "        with open(\"/home/xrspace/Llama/Thesis/E2i/ablition/fs_fulloption_mistake_clinc_gpt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nüîç {len(mistakes)} mistakes saved to fs_alloption_mistake_gpt.json.json\")\n",
    "    return accuracy\n",
    "\n",
    "# 6. Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_formatted_clinc_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fs_fulloption_predict_clinc_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zs clinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [02:47<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to /home/xrspace/Llama/Thesis/E2i/ablition/zs_fulloption_predict_clinc_gpt.json\n",
      "\n",
      "üìä Accuracy Report\n",
      "Total Samples: 225\n",
      "Correct Predictions: 54\n",
      "Accuracy: 24.00%\n",
      "\n",
      "üîç 171 mistakes saved to zs_alloption_mistake_gpt.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Full Banking77 label set\n",
    "clinc150_labels = [\n",
    "    \"restaurant_reviews\", \"nutrition_info\", \"account_blocked\", \"oil_change_how\", \"time\",\n",
    "    \"weather\", \"redeem_rewards\", \"interest_rate\", \"gas_type\", \"accept_reservations\",\n",
    "    \"smart_home\", \"user_name\", \"report_lost_card\", \"repeat\", \"give_weather\",\n",
    "    \"credit_limit_change\", \"change_language\", \"update_playlist\", \"sync_device\", \"schedule_maintenance\",\n",
    "    \"what_are_your_hobbies\", \"book_hotel\", \"cancel_reservation\", \"change_accent\", \"min_payment\",\n",
    "    \"pay_bill\", \"international_visa\", \"calendar\", \"exchange_rate\", \"flip_coin\",\n",
    "    \"do_you_have_pets\", \"balance\", \"tell_joke\", \"last_maintenance\", \"income\",\n",
    "    \"vaccines\", \"reminder_update\", \"order\", \"jump_start\", \"recipe\",\n",
    "    \"meal_suggestion\", \"restaurant_reservation\", \"reset_password\", \"change_password\", \"spending_history\",\n",
    "    \"cancel\", \"user_rating\", \"where_are_you_from\", \"are_you_a_bot\", \"make_reservation\",\n",
    "    \"expiration_date\", \"routing\", \"insurance_change\", \"what_is_your_name\", \"thank_you\",\n",
    "    \"shopping_list\", \"user_feedback\", \"change_speed\", \"plug_type\", \"travel_alert\",\n",
    "    \"traffic\", \"travel_notification\", \"order_checks\", \"bill_balance\", \"improve_credit_score\",\n",
    "    \"report_fraud\", \"spending_limit\", \"directions\", \"credit_score\", \"bill_due\",\n",
    "    \"who_made_you\", \"application_status\", \"apr\", \"how_old_are_you\", \"are_you_real\",\n",
    "    \"direct_deposit\", \"transactions\", \"transfer\", \"card_declined\", \"interest_rate_change\",\n",
    "    \"report_lost_phone\", \"change_user_name\", \"current_location\", \"pto_request\", \"next_song\",\n",
    "    \"change_volume\", \"travel_suggestion\", \"no\", \"maybe\", \"yes\",\n",
    "    \"order_status\", \"confirm_reservation\", \"cook_time\", \"calendar_update\", \"nutrition_plan\",\n",
    "    \"pto_request_status\", \"how_busy\", \"cancel_subscription\", \"exchange_currency\", \"payday\",\n",
    "    \"schedule_meeting\", \"calories\", \"report_charge\", \"car_rental\", \"gas\",\n",
    "    \"how_much\", \"play_music\", \"book_flight\", \"weather_umbrella\", \"book_holiday\",\n",
    "    \"uber\", \"change_organization\", \"meeting_schedule\", \"whisper_mode\", \"what_song\",\n",
    "    \"meaning_of_life\", \"todo_list\", \"card_arrival\", \"next_holiday\", \"change_name\",\n",
    "    \"international_fees\", \"calendar_remove\", \"taxes\", \"vaccination_requirements\", \"passport_renewal\",\n",
    "    \"timezone\", \"reminder\", \"how_many\", \"application_deadline\", \"freeze_account\",\n",
    "    \"what_can_i_ask_you\", \"give_recipe\", \"start_plan\", \"goodbye\", \"what_is_your_gender\",\n",
    "    \"how_do_i_make_a_payment\", \"book_appointment\", \"damaged_card\", \"reset_settings\", \"update_settings\",\n",
    "    \"pto_balance\", \"cancel_appointment\", \"order_cancel\", \"cut_off\", \"report_outage\",\n",
    "    \"reward_balance\", \"update_profile\", \"add_remove_device\", \"fun_fact\", \"oil_change_when\",\n",
    "    \"travel_documents\", \"replacement_card_duration\", \"new_card\", \"roll_dice\", \"who_do_you_work_for\",\n",
    "    \"shopping_list_update\", \"next_event\", \"change_profile_picture\", \"redeem_gift_card\", \"current_weather\",\n",
    "    \"flight_status\", \"new_card_limit\", \"good_morning\", \"new_card_expires\", \"how_long\",\n",
    "    \"where_is_my_refund\", \"definition\", \"bill_due_date\", \"who_are_you\", \"tell_me_about_yourself\"\n",
    "]\n",
    "\n",
    "# 1. Build Zero-Shot prompt\n",
    "def build_prompt(user_input: str) -> str:\n",
    "    options_block = \", \".join(clinc150_labels)\n",
    "    return f\"\"\"Given the sentence: \"{user_input}\"\n",
    "Please select the most possible topic from\n",
    "the following OPTIONS: {options_block}\n",
    "CHOICE:\"\"\"\n",
    "\n",
    "# 2. Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 3. Parse response\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"entities\": \"N/A\",\n",
    "        \"explanation\": \"N/A\",\n",
    "        \"predicted_label\": response.strip().split(\"\\n\")[0]\n",
    "    }\n",
    "\n",
    "# 4. Run classification\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv)  # ‚Üê run on all samples; or use .iloc[:10] to limit\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['text']\n",
    "        true_label = row['label']\n",
    "        prompt = build_prompt(text)\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        result = {\n",
    "            \"id\": int(row['id']),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\": clinc150_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        }\n",
    "        results.append(result)\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to {output_json}\")\n",
    "    return results\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "def evaluate_accuracy(results: List[Dict]):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['true_label'].strip() == r['predicted_label'].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    print(\"\\nüìä Accuracy Report\")\n",
    "    print(f\"Total Samples: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    mistakes = [r for r in results if r['true_label'].strip() != r['predicted_label'].strip()]\n",
    "    if mistakes:\n",
    "        with open(\"/home/xrspace/Llama/Thesis/E2i/ablition/zs_alloption_mistake_gpt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nüîç {len(mistakes)} mistakes saved to zs_alloption_mistake_gpt.json\")\n",
    "    return accuracy\n",
    "\n",
    "# 6. Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_formatted_clinc_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/zs_fulloption_predict_clinc_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "liu54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [01:31<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to: /home/xrspace/Llama/Thesis/E2i/ablition/fulloption_predict_liu_gpt.json\n",
      "\n",
      "üîç Accuracy: 0.00%\n",
      "Mistakes: 60 / 60\n",
      "Mistakes saved to: /home/xrspace/Llama/Thesis/E2i/ablition/fulloption_mistake_liu_gpt.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load few-shot support file\n",
    "with open(\"/home/xrspace/Llama/Thesis/reduce/liu54/fs_liu_samples_gpt4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    FEWSHOT_DB = json.load(f)\n",
    "\n",
    "# Organize few-shot examples by label\n",
    "label_to_example = defaultdict(list)\n",
    "for entry in FEWSHOT_DB:\n",
    "    label_to_example[entry[\"true_label\"]].append(entry)\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"key\"\n",
    "\n",
    "# Define full Banking77 label set\n",
    "liu_54_labels = [\n",
    "    \"alarm_set\", \"alarm_query\", \"alarm_remove\", \"reminder_set\", \"reminder_query\", \"reminder_remove\",\n",
    "    \"timer_set\", \"timer_query\", \"timer_remove\",\n",
    "    \"calendar_set\", \"calendar_query\", \"calendar_remove\",\n",
    "    \"weather_query\",\n",
    "    \"music_play\", \"music_query\", \"music_pause\", \"music_resume\", \"music_next\", \"music_previous\", \"music_repeat\", \"music_shuffle\", \"music_volume_up\", \"music_volume_down\",\n",
    "    \"audiobook_play\", \"audiobook_pause\", \"audiobook_resume\", \"audiobook_next\", \"audiobook_previous\",\n",
    "    \"podcast_play\", \"podcast_pause\", \"podcast_resume\", \"podcast_next\", \"podcast_previous\",\n",
    "    \"news_query\",\n",
    "    \"traffic_query\", \"navigation_set\", \"navigation_cancel\",\n",
    "    \"local_event_query\", \"local_place_query\", \"local_time_query\",\n",
    "    \"date_time_query\",\n",
    "    \"general_greeting\", \"general_ask\", \"general_thanks\", \"general_goodbye\",\n",
    "    \"iot_cleaning\", \"iot_cooking\", \"iot_coffee\", \"iot_temperature_set\", \"iot_temperature_query\", \"iot_light_set\", \"iot_light_query\"\n",
    "]\n",
    "\n",
    "# Build prompt using dynamic few-shot samples (capped at 40 total examples)\n",
    "def build_prompt(user_input: str, topn_labels: List[str]) -> str:\n",
    "    formatted_options = \"\\n\".join(f\"- {label.replace('_', ' ')}\" for label in topn_labels)\n",
    "    few_shots = []\n",
    "    MAX_FEWSHOT = 40\n",
    "\n",
    "    for label in topn_labels:\n",
    "        if label in label_to_example:\n",
    "            examples = label_to_example[label]\n",
    "            sampled = random.sample(examples, min(3, len(examples)))  # Up to 3 per label\n",
    "            for ex in sampled:\n",
    "                few_shots.append(f\"\"\"Example:\n",
    "Query: \"{ex['text']}\"\n",
    "Roles: {ex['entities']}\n",
    "Reasoning: {ex['explanation']}\n",
    "Label: {label}\n",
    "---\"\"\")\n",
    "                if len(few_shots) >= MAX_FEWSHOT:\n",
    "                    break\n",
    "        if len(few_shots) >= MAX_FEWSHOT:\n",
    "            break\n",
    "\n",
    "    few_shot_block = \"\\n\".join(few_shots)\n",
    "    return f\"\"\"You are an intelligent assistant for intent classification in banking queries.\n",
    "{few_shot_block}\n",
    "Instructions:\n",
    "1. Extract the semantic elements from the user query as structured roles:\n",
    "   - action (what is being done)\n",
    "   - object (what it‚Äôs done to)\n",
    "   - target (who or what is affected)\n",
    "   - temporal (time-related references, if any)\n",
    "   - intent_clue (phrases showing intent)\n",
    "2. Use the extracted roles to reason about how the query aligns with each of the options below.\n",
    "3. For each option, explain why it does or does not match the extracted semantics.\n",
    "4. Finally, choose the most appropriate intent label from the given options.\n",
    "5. Return final decision in the original snake_case label.\n",
    "OPTIONS:\n",
    "{formatted_options}\n",
    "---\n",
    "QUERY: {user_input}\n",
    "Respond in the following format:\n",
    "```json\n",
    "{{\n",
    "  \"roles\": {{\n",
    "    \"action\": \"...\",\n",
    "    \"object\": \"...\",\n",
    "    \"target\": \"...\",\n",
    "    \"temporal\": \"...\",\n",
    "    \"intent_clue\": \"...\"\n",
    "  }},\n",
    "  \"reasoning\": \"...\",\n",
    "  \"label\": \"...\"\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "# Query GPT model\n",
    "def query_model(prompt: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant specializing in intent classification.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=600\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Parse structured output\n",
    "def parse_response(response: str) -> Dict[str, str]:\n",
    "    try:\n",
    "        json_part = re.search(r\"\\{.*\\}\", response, re.DOTALL).group(0)\n",
    "        parsed_json = json.loads(json_part)\n",
    "        roles = parsed_json.get(\"roles\", {})\n",
    "        explanation = parsed_json.get(\"reasoning\", \"N/A\")\n",
    "        predicted_label = parsed_json.get(\"label\", \"Unknown\")\n",
    "        return {\n",
    "            \"entities\": json.dumps(roles, ensure_ascii=False),\n",
    "            \"explanation\": explanation,\n",
    "            \"predicted_label\": predicted_label\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Parsing error:\", e)\n",
    "        return {\"entities\": \"N/A\", \"explanation\": \"N/A\", \"predicted_label\": \"Unknown\"}\n",
    "\n",
    "# Main evaluation pipeline\n",
    "def run_ner_cot(input_csv: str, output_json: str):\n",
    "    df = pd.read_csv(input_csv).iloc[:60]\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row[\"text\"]\n",
    "        true_label = row[\"label\"]\n",
    "        prompt = build_prompt(text, liu_54_labels)  # Full label set\n",
    "        response = query_model(prompt)\n",
    "        parsed = parse_response(response)\n",
    "        results.append({\n",
    "            \"id\": int(row[\"id\"]),\n",
    "            \"text\": text,\n",
    "            \"true_label\": true_label,\n",
    "            \"top_k_predictions\":liu_54_labels,\n",
    "            \"entities\": parsed[\"entities\"],\n",
    "            \"explanation\": parsed[\"explanation\"],\n",
    "            \"predicted_label\": parsed[\"predicted_label\"]\n",
    "        })\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Predictions saved to: {output_json}\")\n",
    "    return results\n",
    "\n",
    "# Accuracy check\n",
    "def evaluate_accuracy(results: List[Dict], mistake_file: str = \"fulloption_mistake_liu_gpt.json\"):\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r[\"true_label\"].strip() == r[\"predicted_label\"].strip())\n",
    "    accuracy = correct / total if total else 0\n",
    "    mistakes = [r for r in results if r[\"true_label\"].strip() != r[\"predicted_label\"].strip()]\n",
    "    print(f\"\\nüîç Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"Mistakes: {len(mistakes)} / {total}\")\n",
    "    if mistakes:\n",
    "        with open(mistake_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(mistakes, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Mistakes saved to: {mistake_file}\")\n",
    "    else:\n",
    "        print(\"üéâ No mistakes! Perfect predictions.\")\n",
    "    return accuracy\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"/home/xrspace/Llama/Thesis/E2i/ablition/maccot_formatted_liu_no_topk.csv\"\n",
    "    output_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fulloption_predict_liu_gpt.json\"\n",
    "    mistake_json = \"/home/xrspace/Llama/Thesis/E2i/ablition/fulloption_mistake_liu_gpt.json\"\n",
    "    results = run_ner_cot(input_csv, output_json)\n",
    "    evaluate_accuracy(results, mistake_file=mistake_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-xut4REbk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
